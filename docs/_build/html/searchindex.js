Search.setIndex({"docnames": ["RAVE", "RAVE.common", "RAVE.eye_tracker", "RAVE.facial_detection", "examples", "index"], "filenames": ["RAVE.rst", "RAVE.common.rst", "RAVE.eye_tracker.rst", "RAVE.facial_detection.rst", "examples.rst", "index.rst"], "titles": ["RAVE", "common", "eye_tracker", "facial_detection", "Examples", "Home"], "terms": {"common": 0, "dataset": [0, 2, 3], "dataset_dir": [0, 1], "images_dir": [0, 1], "images_file_extens": [0, 1], "labels_dir": [0, 1], "test_dir": [0, 1], "training_dir": [0, 1], "validation_dir": [0, 1], "__getitem__": [0, 1], "__init__": [0, 1], "__len__": [0, 1], "__module__": [0, 1], "__parameters__": [0, 1], "get_image_and_label_from_image_path": [0, 1], "get_image_and_label_on_disk": [0, 1], "get_multiple_workers_safe_list_of_path": [0, 1], "get_test_sub_dataset": [0, 1, 2, 3], "get_training_sub_dataset": [0, 1, 2, 3], "get_validation_sub_dataset": [0, 1, 2, 3], "datasetbuild": [0, 2], "annotations_dir": [0, 1], "root_path": [0, 1], "videos_dir": [0, 1, 2], "create_directory_if_does_not_exist": [0, 1], "create_images_dataset_with_one_video": [0, 1], "create_images_of_one_video_group": [0, 1], "get_build": [0, 1, 2], "parse_current_annot": [0, 1, 2], "process_fram": [0, 1, 2], "process_image_label_pair": [0, 1, 2], "save_image_label_pair": [0, 1], "trainer": 0, "model_info_file_nam": [0, 1], "training_sessions_dir": [0, 1], "compute_training_loss": [0, 1], "compute_validation_loss": [0, 1], "load_best_model": [0, 1], "load_model_and_training_info": [0, 1], "save_model_and_training_info": [0, 1], "terminate_training_thread": [0, 1], "train_with_valid": [0, 1], "update_plot": [0, 1], "image_util": 0, "apply_image_rot": [0, 1], "apply_image_transl": [0, 1], "apply_image_translation_and_rot": [0, 1], "box_iou": [0, 1], "check_frontal_fac": [0, 1], "clip_coord": [0, 1], "do_affine_grid_oper": [0, 1], "giou": [0, 1], "intersect": [0, 1], "inverse_norm": [0, 1], "opencv_image_to_tensor": [0, 1], "scale_coord": [0, 1], "scale_coords_landmark": [0, 1], "tensor_to_opencv_imag": [0, 1], "xywh2xyxi": [0, 1], "xyxy2xywh": [0, 1], "eye_track": 0, "eyetrackerdataset": 0, "crop_siz": [0, 1, 2], "eye_tracker_dir_path": [0, 2], "image_dimens": [0, 1, 2, 3], "training_mean": [0, 1, 2, 3], "training_std": [0, 1, 2, 3], "eyetrackerdatasetonlinedataaugment": [0, 2], "eyetrackerfilm": [0, 2], "acquisition_height": [0, 2], "acquisition_width": [0, 2], "end": [0, 1, 2], "eyetrackerinferencedataset": [0, 2], "eyetrackerdatasetbuild": 0, "create_dataset": [0, 2], "generate_dataset": [0, 2], "eyetrackerdatasetbuilderofflinedataaugment": [0, 2], "apply_translation_and_rot": [0, 2], "videosunpack": [0, 2], "tmp_path": [0, 2], "eyetrackermodel": 0, "forward": [0, 2], "train": [0, 1, 2, 3], "normalizedellips": 0, "crop": [0, 2], "get_from_list": [0, 2], "get_from_opencv_ellips": [0, 2], "rotate_around_image_cent": [0, 2], "to_list": [0, 2], "ellipse_util": 0, "draw_ellipse_on_imag": [0, 2], "ellipse_loss_funct": [0, 2], "get_points_of_ellips": [0, 2], "facial_detect": 0, "facedetectiondataset": 0, "face_detection_dir_path": [0, 3], "facedetectionmodel": 0, "fpshelper": 0, "fp": [0, 3], "getfp": [0, 3], "setfp": [0, 3], "start": [0, 3, 4], "writefpstofram": [0, 3], "class": [1, 2, 3], "sub_dataset_dir": [1, 2, 3], "base": [1, 2, 3], "handl": [1, 2, 3], "pair": [1, 2, 3], "imag": [1, 2, 3], "label": [1, 2, 3], "ar": [1, 2, 3], "disk": [1, 2, 3], "paramet": [1, 2, 3], "float": [1, 2], "mean": [1, 2], "pixel": [1, 2], "valu": [1, 2], "std": 1, "rooth_path": 1, "string": [1, 2, 3], "root": 1, "path": [1, 2], "name": [1, 2, 3], "directori": [1, 2, 3], "sub": [1, 2, 3], "tupl": [1, 2], "dimens": 1, "shape": [1, 3], "3": [1, 2, 3], "height": [1, 2, 3], "width": [1, 2, 3], "png": 1, "test": [1, 2, 3], "valid": [1, 2, 3], "idx": 1, "method": [1, 2], "must": [1, 2], "overwritten": [1, 2], "thi": [1, 2], "us": [1, 2, 3], "get": [1, 2, 3, 4], "an": [1, 2, 3], "int": [1, 2], "index": [1, 2, 5], "return": [1, 2, 3], "type": [1, 2, 3], "constructor": 1, "list": [1, 2], "each": [1, 2], "channel": 1, "subdataset": 1, "standard": 1, "deviat": 1, "The": [1, 2, 3, 4], "full": 1, "ey": [1, 2], "tracker": [1, 2], "current": [1, 2], "form": 1, "number": [1, 2], "element": 1, "rave": [1, 2, 3, 4, 5], "image_path": 1, "str": 1, "static": [1, 2, 3], "build": [1, 2], "prevent": 1, "memori": 1, "leak": 1, "happen": 1, "multipl": 1, "dataload": 1, "worker": 1, "http": [1, 2], "gist": 1, "github": 1, "com": [1, 2], "mprostock": 1, "2850f3cd465155689052f0fa3a177a50": 1, "which": [1, 2], "its": [1, 2], "file": [1, 2], "abstract": 1, "video": [1, 2, 5], "output_dir_path": [1, 2], "log_nam": [1, 2], "source_dir": [1, 2], "none": [1, 2], "abc": 1, "It": [1, 2], "take": [1, 2], "extract": [1, 2], "frame": [1, 2, 3], "save": [1, 2], "them": [1, 2], "correspond": [1, 2], "also": [1, 2], "appli": [1, 2], "data": [1, 2], "augment": [1, 2], "transform": [1, 2], "belong": 1, "contain": 1, "displai": 1, "alongsid": 1, "progress": 1, "bar": 1, "termin": 1, "annot": [1, 2], "home": [1, 2], "runner": [1, 2], "work": [1, 2], "doc": [1, 2], "creat": [1, 2], "doe": [1, 2], "exist": 1, "file_nam": [1, 2], "video_path": 1, "One": 1, "per": 1, "repres": [1, 2], "i": [1, 2, 3, 5], "present": 1, "info": 1, "one": [1, 2], "object": [1, 2, 3], "input_image_width": [1, 2], "input_image_height": [1, 2], "pars": [1, 2], "ellips": [1, 2], "defin": [1, 2], "opencv": [1, 2, 3], "all": [1, 2], "true": [1, 2], "wa": [1, 2], "success": [1, 2], "fals": [1, 2], "wasn": [1, 2], "t": [1, 2], "bool": [1, 2], "need": [1, 2], "befor": 1, "numpi": [1, 2], "arrai": [1, 2], "process": [1, 2, 5], "pytorch": [1, 2], "tensor": [1, 2], "from": [1, 2], "specif": 1, "param": 1, "": [1, 2], "output_image_tensor": [1, 2], "training_load": 1, "validation_load": 1, "loss_funct": 1, "devic": [1, 2], "model": [1, 2], "optim": 1, "schedul": 1, "root_dir_path": 1, "continue_train": 1, "neural": [1, 2], "network": [1, 2], "functor": 1, "loss": [1, 2], "function": [1, 2], "comput": [1, 2, 3], "perform": [1, 2], "modul": [1, 2], "updat": 1, "weight": 1, "dure": 1, "_lrschedul": 1, "learn": 1, "rate": 1, "whether": 1, "continu": 1, "checkpoint": 1, "saved_model": 1, "pth": 1, "training_sess": 1, "epoch": 1, "model_dir_path": 1, "best": 1, "version": 1, "torch": 1, "most": 1, "like": 1, "cpu": 1, "cuda": 1, "load": 1, "necessari": 1, "inform": 1, "now": 1, "some": [1, 2], "other": 1, "time": [1, 2, 3], "thread": 1, "check": [1, 2], "user": 1, "want": [1, 3], "stop": 1, "have": 1, "been": [1, 2], "execut": [1, 2], "nb_epoch": 1, "main": [1, 2], "plot": 1, "show": 1, "so": [1, 2], "far": 1, "image_tensor": 1, "rotation_angle_extremum": 1, "0": [1, 2, 3], "1": [1, 2, 3], "A": [1, 2], "oper": [1, 2], "rotat": [1, 2], "randomli": [1, 2], "select": 1, "angl": [1, 2], "rang": 1, "should": [1, 2], "instead": 1, "you": [1, 4], "wish": 1, "know": 1, "amplitud": 1, "option": [1, 2], "min": 1, "max": [1, 2], "default": [1, 2], "x_extremum": 1, "2": [1, 2], "y_extremum": 1, "translat": [1, 2], "x": [1, 2], "y": [1, 2], "respect": 1, "offset": 1, "therot": 1, "box1": 1, "box2": 1, "over": 1, "union": 1, "jaccard": 1, "box": 1, "both": 1, "set": 1, "expect": 1, "x1": 1, "y1": 1, "x2": 1, "y2": 1, "format": [1, 2], "n": 1, "4": 1, "m": 1, "nxm": 1, "matrix": 1, "pairwis": 1, "iou": 1, "everi": 1, "boxes1": 1, "boxes2": 1, "facial_landmark": 1, "thresh_dist_low": 1, "7": 1, "thresh_dist_high": 1, "thresh_high_std": 1, "5": [1, 2], "taken": 1, "tan": 1, "tran": 1, "nguyen": 1, "h": [1, 2], "soan": 1, "duong": 1, "hui": 1, "d": 1, "ta": 1, "chanh": 1, "tr": 1, "trung": 1, "bui": 1, "steven": 1, "q": 1, "truong": 1, "resort": 1, "id": 1, "recoveri": 1, "multi": 1, "face": 1, "track": 1, "surveil": 1, "camera": 1, "ieee": 1, "2021": 1, "ratio": 1, "threshold": 1, "lower": 1, "bound": 1, "higher": 1, "diagon": 1, "distanc": [1, 2], "If": 1, "frontal": 1, "img_shap": 1, "clip": 1, "xyxi": 1, "phi": [1, 2], "affin": 1, "magnitud": 1, "bbox1": 1, "bbox2": 1, "gener": [1, 2], "score": 1, "even": 1, "when": 1, "overlap": 1, "paper": 1, "arxiv": 1, "org": 1, "pdf": 1, "1911": 1, "08287": 1, "np": 1, "ndarrai": [1, 3], "xywh": 1, "coord": 1, "scale": 1, "smallest": 1, "area": 1, "undo": 1, "normal": [1, 2], "pass": [1, 2], "unorm": 1, "bgr": 1, "rgb": 1, "img1_shap": 1, "img0_shap": 1, "ratio_pad": 1, "rescal": 1, "convert": 1, "nx4": 1, "w": 1, "where": [1, 2], "xy1": 1, "top": [1, 2], "left": [1, 2], "xy2": 1, "bottom": 1, "right": [1, 3], "50": 2, "390": 2, "520": 2, "240": 2, "320": 2, "485": 2, "456": 2, "406": 2, "229": 2, "224": 2, "225": 2, "inherit": 2, "overwrit": 2, "certain": 2, "order": 2, "do": 2, "onlin": 2, "opencv_devic": 2, "manag": 2, "live": 2, "480": 2, "640": 2, "call": 2, "program": 2, "free": [2, 5], "real": 2, "feed": 2, "infer": 2, "is_secondary_dataset": 2, "alreadi": 2, "built": 2, "otherwis": 2, "offlin": 2, "reflect": 2, "chang": 2, "parent": 2, "unpack": 2, "constitut": 2, "dump": 2, "temporari": 2, "can": [2, 3], "tmp": 2, "builder": 2, "tool": 2, "processed_fram": 2, "original_height": 2, "original_width": 2, "To": [2, 3], "target": 2, "detect": 2, "pupil": 2, "specifi": 2, "how": 2, "sigmoid": 2, "limit": 2, "ouput": 2, "domain": 2, "converg": 2, "more": 2, "easili": 2, "between": 2, "axi": 2, "pi": 2, "radian": 2, "theta": 2, "For": 2, "exampl": 2, "input": 2, "predict": 2, "k": 2, "b": 2, "five": 2, "center": 2, "posit": 2, "horizont": 2, "vertic": 2, "length": 2, "rel": 2, "longer": 2, "rather": 2, "new": 2, "crop_bbox": 2, "crope": 2, "e": 2, "associ": 2, "ha": 2, "origin": 2, "pre": 2, "center_x": 2, "ellipse_width": 2, "center_i": 2, "ellipse_height": 2, "coordin": 2, "around": 2, "point": 2, "rad": 2, "serial": 2, "color": 2, "255": 2, "thick": 2, "draw": 2, "drawn": 2, "custom": 2, "develop": 2, "becaus": 2, "mseloss": 2, "directli": 2, "give": 2, "good": 2, "result": 2, "session": 2, "lie": 2, "euclidean": 2, "metric": 2, "number_of_point": 2, "polar": 2, "math": 2, "stackexchang": 2, "question": 2, "2645689": 2, "what": 2, "parametr": 2, "equat": 2, "given": 2, "rotatio": 2, "face_detect": 3, "800": 3, "0648": 3, "095": 3, "0119": 3, "0695": 3, "0609": 3, "0581": 3, "accessor": 3, "reset": 3, "part": 3, "we": 3, "after": 3, "init": 3, "write": 3, "follow": 4, "help": 4, "come": 4, "soon": 4, "proof": 5, "concept": 5, "aim": 5, "demonstr": 5, "possibl": 5, "combin": 5, "audio": 5, "hear": 5, "aid": 5, "open": 5, "sourc": 5}, "objects": {"RAVE.common": [[1, 0, 0, "-", "Dataset"], [1, 0, 0, "-", "DatasetBuilder"], [1, 0, 0, "-", "Trainer"], [1, 0, 0, "-", "image_utils"]], "RAVE.common.Dataset": [[1, 1, 1, "", "Dataset"]], "RAVE.common.Dataset.Dataset": [[1, 2, 1, "", "DATASET_DIR"], [1, 2, 1, "", "IMAGES_DIR"], [1, 2, 1, "", "IMAGES_FILE_EXTENSION"], [1, 2, 1, "", "LABELS_DIR"], [1, 2, 1, "", "TEST_DIR"], [1, 2, 1, "", "TRAINING_DIR"], [1, 2, 1, "", "VALIDATION_DIR"], [1, 3, 1, "", "__getitem__"], [1, 3, 1, "", "__init__"], [1, 3, 1, "", "__len__"], [1, 2, 1, "", "__module__"], [1, 2, 1, "", "__parameters__"], [1, 3, 1, "", "get_image_and_label_from_image_path"], [1, 3, 1, "", "get_image_and_label_on_disk"], [1, 3, 1, "", "get_multiple_workers_safe_list_of_paths"], [1, 3, 1, "", "get_test_sub_dataset"], [1, 3, 1, "", "get_training_sub_dataset"], [1, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.common.DatasetBuilder": [[1, 1, 1, "", "DatasetBuilder"]], "RAVE.common.DatasetBuilder.DatasetBuilder": [[1, 2, 1, "", "ANNOTATIONS_DIR"], [1, 2, 1, "", "ROOT_PATH"], [1, 2, 1, "", "VIDEOS_DIR"], [1, 3, 1, "", "create_directory_if_does_not_exist"], [1, 3, 1, "", "create_images_dataset_with_one_video"], [1, 3, 1, "", "create_images_of_one_video_group"], [1, 3, 1, "", "get_builders"], [1, 3, 1, "", "parse_current_annotation"], [1, 3, 1, "", "process_frame"], [1, 3, 1, "", "process_image_label_pair"], [1, 3, 1, "", "save_image_label_pair"]], "RAVE.common.Trainer": [[1, 1, 1, "", "Trainer"]], "RAVE.common.Trainer.Trainer": [[1, 2, 1, "", "MODEL_INFO_FILE_NAME"], [1, 2, 1, "", "TRAINING_SESSIONS_DIR"], [1, 3, 1, "", "compute_training_loss"], [1, 3, 1, "", "compute_validation_loss"], [1, 3, 1, "", "load_best_model"], [1, 3, 1, "", "load_model_and_training_info"], [1, 3, 1, "", "save_model_and_training_info"], [1, 3, 1, "", "terminate_training_thread"], [1, 3, 1, "", "train_with_validation"], [1, 3, 1, "", "update_plot"]], "RAVE.common.image_utils": [[1, 4, 1, "", "apply_image_rotation"], [1, 4, 1, "", "apply_image_translation"], [1, 4, 1, "", "apply_image_translation_and_rotation"], [1, 4, 1, "", "box_iou"], [1, 4, 1, "", "check_frontal_face"], [1, 4, 1, "", "clip_coords"], [1, 4, 1, "", "do_affine_grid_operation"], [1, 4, 1, "", "giou"], [1, 4, 1, "", "intersection"], [1, 4, 1, "", "inverse_normalize"], [1, 4, 1, "", "opencv_image_to_tensor"], [1, 4, 1, "", "scale_coords"], [1, 4, 1, "", "scale_coords_landmarks"], [1, 4, 1, "", "tensor_to_opencv_image"], [1, 4, 1, "", "xywh2xyxy"], [1, 4, 1, "", "xyxy2xywh"]], "RAVE.eye_tracker": [[2, 0, 0, "-", "EyeTrackerDataset"], [2, 0, 0, "-", "EyeTrackerDatasetBuilder"], [2, 0, 0, "-", "EyeTrackerModel"], [2, 0, 0, "-", "NormalizedEllipse"], [2, 0, 0, "-", "ellipse_util"]], "RAVE.eye_tracker.EyeTrackerDataset": [[2, 1, 1, "", "EyeTrackerDataset"], [2, 1, 1, "", "EyeTrackerDatasetOnlineDataAugmentation"], [2, 1, 1, "", "EyeTrackerFilm"], [2, 1, 1, "", "EyeTrackerInferenceDataset"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset": [[2, 2, 1, "", "CROP_SIZE"], [2, 2, 1, "", "EYE_TRACKER_DIR_PATH"], [2, 2, 1, "", "IMAGE_DIMENSIONS"], [2, 2, 1, "", "TRAINING_MEAN"], [2, 2, 1, "", "TRAINING_STD"], [2, 3, 1, "", "get_test_sub_dataset"], [2, 3, 1, "", "get_training_sub_dataset"], [2, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm": [[2, 2, 1, "", "ACQUISITION_HEIGHT"], [2, 2, 1, "", "ACQUISITION_WIDTH"], [2, 3, 1, "", "end"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset": [[2, 2, 1, "", "ACQUISITION_HEIGHT"], [2, 2, 1, "", "ACQUISITION_WIDTH"], [2, 3, 1, "", "end"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder": [[2, 1, 1, "", "EyeTrackerDatasetBuilder"], [2, 1, 1, "", "EyeTrackerDatasetBuilderOfflineDataAugmentation"], [2, 1, 1, "", "VideosUnpacker"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder": [[2, 3, 1, "", "create_datasets"], [2, 3, 1, "", "generate_dataset"], [2, 3, 1, "", "get_builders"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilderOfflineDataAugmentation": [[2, 3, 1, "", "apply_translation_and_rotation"], [2, 3, 1, "", "process_frame"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker": [[2, 2, 1, "", "TMP_PATH"], [2, 3, 1, "", "get_builders"], [2, 3, 1, "", "parse_current_annotation"], [2, 3, 1, "", "process_image_label_pair"]], "RAVE.eye_tracker.EyeTrackerModel": [[2, 1, 1, "", "EyeTrackerModel"]], "RAVE.eye_tracker.EyeTrackerModel.EyeTrackerModel": [[2, 3, 1, "", "forward"], [2, 2, 1, "", "training"]], "RAVE.eye_tracker.NormalizedEllipse": [[2, 1, 1, "", "NormalizedEllipse"]], "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse": [[2, 3, 1, "", "crop"], [2, 3, 1, "", "get_from_list"], [2, 3, 1, "", "get_from_opencv_ellipse"], [2, 3, 1, "", "rotate_around_image_center"], [2, 3, 1, "", "to_list"]], "RAVE.eye_tracker.ellipse_util": [[2, 4, 1, "", "draw_ellipse_on_image"], [2, 4, 1, "", "ellipse_loss_function"], [2, 4, 1, "", "get_points_of_ellipses"]], "RAVE.face_detection": [[3, 0, 0, "-", "FaceDetectionDataset"], [3, 0, 0, "-", "fpsHelper"]], "RAVE.face_detection.FaceDetectionDataset": [[3, 1, 1, "", "FaceDetectionDataset"]], "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset": [[3, 2, 1, "", "FACE_DETECTION_DIR_PATH"], [3, 2, 1, "", "IMAGE_DIMENSIONS"], [3, 2, 1, "", "TRAINING_MEAN"], [3, 2, 1, "", "TRAINING_STD"], [3, 3, 1, "", "get_test_sub_dataset"], [3, 3, 1, "", "get_training_sub_dataset"], [3, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.face_detection.fpsHelper": [[3, 1, 1, "", "FPS"]], "RAVE.face_detection.fpsHelper.FPS": [[3, 3, 1, "", "getFps"], [3, 3, 1, "", "setFps"], [3, 3, 1, "", "start"], [3, 3, 1, "", "writeFpsToFrame"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"rave": 0, "common": 1, "dataset": 1, "datasetbuild": 1, "trainer": 1, "image_util": 1, "eye_track": 2, "eyetrackerdataset": 2, "eyetrackerdatasetbuild": 2, "eyetrackermodel": 2, "normalizedellips": 2, "ellipse_util": 2, "facial_detect": 3, "facedetectiondataset": 3, "facedetectionmodel": 3, "fpshelper": 3, "exampl": 4, "home": 5}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"RAVE": [[0, "rave"]], "common": [[1, "common"]], "Dataset": [[1, "module-RAVE.common.Dataset"]], "DatasetBuilder": [[1, "module-RAVE.common.DatasetBuilder"]], "Trainer": [[1, "module-RAVE.common.Trainer"]], "image_utils": [[1, "module-RAVE.common.image_utils"]], "eye_tracker": [[2, "eye-tracker"]], "EyeTrackerDataset": [[2, "module-RAVE.eye_tracker.EyeTrackerDataset"]], "EyeTrackerDatasetBuilder": [[2, "module-RAVE.eye_tracker.EyeTrackerDatasetBuilder"]], "EyeTrackerModel": [[2, "module-RAVE.eye_tracker.EyeTrackerModel"]], "NormalizedEllipse": [[2, "module-RAVE.eye_tracker.NormalizedEllipse"]], "ellipse_util": [[2, "module-RAVE.eye_tracker.ellipse_util"]], "facial_detection": [[3, "facial-detection"]], "FaceDetectionDataset": [[3, "module-RAVE.face_detection.FaceDetectionDataset"]], "FaceDetectionModel": [[3, "facedetectionmodel"]], "FpsHelper": [[3, "module-RAVE.face_detection.fpsHelper"]], "Examples": [[4, "examples"]], "Home": [[5, "home"]]}, "indexentries": {"annotations_dir (datasetbuilder attribute)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.ANNOTATIONS_DIR"]], "dataset_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.DATASET_DIR"]], "dataset (class in rave.common.dataset)": [[1, "RAVE.common.Dataset.Dataset"]], "datasetbuilder (class in rave.common.datasetbuilder)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder"]], "images_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.IMAGES_DIR"]], "images_file_extension (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.IMAGES_FILE_EXTENSION"]], "labels_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.LABELS_DIR"]], "model_info_file_name (trainer attribute)": [[1, "RAVE.common.Trainer.Trainer.MODEL_INFO_FILE_NAME"]], "rave.common.dataset": [[1, "module-RAVE.common.Dataset"]], "rave.common.datasetbuilder": [[1, "module-RAVE.common.DatasetBuilder"]], "rave.common.trainer": [[1, "module-RAVE.common.Trainer"]], "rave.common.image_utils": [[1, "module-RAVE.common.image_utils"]], "root_path (datasetbuilder attribute)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.ROOT_PATH"]], "test_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.TEST_DIR"]], "training_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.TRAINING_DIR"]], "training_sessions_dir (trainer attribute)": [[1, "RAVE.common.Trainer.Trainer.TRAINING_SESSIONS_DIR"]], "trainer (class in rave.common.trainer)": [[1, "RAVE.common.Trainer.Trainer"]], "validation_dir (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.VALIDATION_DIR"]], "videos_dir (datasetbuilder attribute)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.VIDEOS_DIR"]], "__getitem__() (dataset method)": [[1, "RAVE.common.Dataset.Dataset.__getitem__"]], "__init__() (dataset method)": [[1, "RAVE.common.Dataset.Dataset.__init__"]], "__len__() (dataset method)": [[1, "RAVE.common.Dataset.Dataset.__len__"]], "__module__ (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.__module__"]], "__parameters__ (dataset attribute)": [[1, "RAVE.common.Dataset.Dataset.__parameters__"]], "apply_image_rotation() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.apply_image_rotation"]], "apply_image_translation() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.apply_image_translation"]], "apply_image_translation_and_rotation() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.apply_image_translation_and_rotation"]], "box_iou() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.box_iou"]], "check_frontal_face() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.check_frontal_face"]], "clip_coords() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.clip_coords"]], "compute_training_loss() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.compute_training_loss"]], "compute_validation_loss() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.compute_validation_loss"]], "create_directory_if_does_not_exist() (datasetbuilder static method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.create_directory_if_does_not_exist"]], "create_images_dataset_with_one_video() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.create_images_dataset_with_one_video"]], "create_images_of_one_video_group() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.create_images_of_one_video_group"]], "do_affine_grid_operation() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.do_affine_grid_operation"]], "get_builders() (datasetbuilder static method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.get_builders"]], "get_image_and_label_from_image_path() (dataset method)": [[1, "RAVE.common.Dataset.Dataset.get_image_and_label_from_image_path"]], "get_image_and_label_on_disk() (dataset method)": [[1, "RAVE.common.Dataset.Dataset.get_image_and_label_on_disk"]], "get_multiple_workers_safe_list_of_paths() (dataset static method)": [[1, "RAVE.common.Dataset.Dataset.get_multiple_workers_safe_list_of_paths"]], "get_test_sub_dataset() (dataset static method)": [[1, "RAVE.common.Dataset.Dataset.get_test_sub_dataset"]], "get_training_sub_dataset() (dataset static method)": [[1, "RAVE.common.Dataset.Dataset.get_training_sub_dataset"]], "get_validation_sub_dataset() (dataset static method)": [[1, "RAVE.common.Dataset.Dataset.get_validation_sub_dataset"]], "giou() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.giou"]], "intersection() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.intersection"]], "inverse_normalize() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.inverse_normalize"]], "load_best_model() (trainer static method)": [[1, "RAVE.common.Trainer.Trainer.load_best_model"]], "load_model_and_training_info() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.load_model_and_training_info"]], "module": [[1, "module-RAVE.common.Dataset"], [1, "module-RAVE.common.DatasetBuilder"], [1, "module-RAVE.common.Trainer"], [1, "module-RAVE.common.image_utils"], [2, "module-RAVE.eye_tracker.EyeTrackerDataset"], [2, "module-RAVE.eye_tracker.EyeTrackerDatasetBuilder"], [2, "module-RAVE.eye_tracker.EyeTrackerModel"], [2, "module-RAVE.eye_tracker.NormalizedEllipse"], [2, "module-RAVE.eye_tracker.ellipse_util"], [3, "module-RAVE.face_detection.FaceDetectionDataset"], [3, "module-RAVE.face_detection.fpsHelper"]], "opencv_image_to_tensor() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.opencv_image_to_tensor"]], "parse_current_annotation() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.parse_current_annotation"]], "process_frame() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.process_frame"]], "process_image_label_pair() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.process_image_label_pair"]], "save_image_label_pair() (datasetbuilder method)": [[1, "RAVE.common.DatasetBuilder.DatasetBuilder.save_image_label_pair"]], "save_model_and_training_info() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.save_model_and_training_info"]], "scale_coords() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.scale_coords"]], "scale_coords_landmarks() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.scale_coords_landmarks"]], "tensor_to_opencv_image() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.tensor_to_opencv_image"]], "terminate_training_thread() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.terminate_training_thread"]], "train_with_validation() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.train_with_validation"]], "update_plot() (trainer method)": [[1, "RAVE.common.Trainer.Trainer.update_plot"]], "xywh2xyxy() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.xywh2xyxy"]], "xyxy2xywh() (in module rave.common.image_utils)": [[1, "RAVE.common.image_utils.xyxy2xywh"]], "acquisition_height (eyetrackerfilm attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm.ACQUISITION_HEIGHT"]], "acquisition_height (eyetrackerinferencedataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset.ACQUISITION_HEIGHT"]], "acquisition_width (eyetrackerfilm attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm.ACQUISITION_WIDTH"]], "acquisition_width (eyetrackerinferencedataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset.ACQUISITION_WIDTH"]], "crop_size (eyetrackerdataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.CROP_SIZE"]], "eye_tracker_dir_path (eyetrackerdataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.EYE_TRACKER_DIR_PATH"]], "eyetrackerdataset (class in rave.eye_tracker.eyetrackerdataset)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset"]], "eyetrackerdatasetbuilder (class in rave.eye_tracker.eyetrackerdatasetbuilder)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder"]], "eyetrackerdatasetbuilderofflinedataaugmentation (class in rave.eye_tracker.eyetrackerdatasetbuilder)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilderOfflineDataAugmentation"]], "eyetrackerdatasetonlinedataaugmentation (class in rave.eye_tracker.eyetrackerdataset)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDatasetOnlineDataAugmentation"]], "eyetrackerfilm (class in rave.eye_tracker.eyetrackerdataset)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm"]], "eyetrackerinferencedataset (class in rave.eye_tracker.eyetrackerdataset)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset"]], "eyetrackermodel (class in rave.eye_tracker.eyetrackermodel)": [[2, "RAVE.eye_tracker.EyeTrackerModel.EyeTrackerModel"]], "image_dimensions (eyetrackerdataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.IMAGE_DIMENSIONS"]], "normalizedellipse (class in rave.eye_tracker.normalizedellipse)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse"]], "rave.eye_tracker.eyetrackerdataset": [[2, "module-RAVE.eye_tracker.EyeTrackerDataset"]], "rave.eye_tracker.eyetrackerdatasetbuilder": [[2, "module-RAVE.eye_tracker.EyeTrackerDatasetBuilder"]], "rave.eye_tracker.eyetrackermodel": [[2, "module-RAVE.eye_tracker.EyeTrackerModel"]], "rave.eye_tracker.normalizedellipse": [[2, "module-RAVE.eye_tracker.NormalizedEllipse"]], "rave.eye_tracker.ellipse_util": [[2, "module-RAVE.eye_tracker.ellipse_util"]], "tmp_path (videosunpacker attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker.TMP_PATH"]], "training_mean (eyetrackerdataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.TRAINING_MEAN"]], "training_std (eyetrackerdataset attribute)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.TRAINING_STD"]], "videosunpacker (class in rave.eye_tracker.eyetrackerdatasetbuilder)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker"]], "apply_translation_and_rotation() (eyetrackerdatasetbuilderofflinedataaugmentation method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilderOfflineDataAugmentation.apply_translation_and_rotation"]], "create_datasets() (eyetrackerdatasetbuilder static method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder.create_datasets"]], "crop() (normalizedellipse method)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse.crop"]], "draw_ellipse_on_image() (in module rave.eye_tracker.ellipse_util)": [[2, "RAVE.eye_tracker.ellipse_util.draw_ellipse_on_image"]], "ellipse_loss_function() (in module rave.eye_tracker.ellipse_util)": [[2, "RAVE.eye_tracker.ellipse_util.ellipse_loss_function"]], "end() (eyetrackerfilm method)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm.end"]], "end() (eyetrackerinferencedataset method)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset.end"]], "forward() (eyetrackermodel method)": [[2, "RAVE.eye_tracker.EyeTrackerModel.EyeTrackerModel.forward"]], "generate_dataset() (eyetrackerdatasetbuilder method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder.generate_dataset"]], "get_builders() (eyetrackerdatasetbuilder static method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder.get_builders"]], "get_builders() (videosunpacker static method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker.get_builders"]], "get_from_list() (normalizedellipse static method)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse.get_from_list"]], "get_from_opencv_ellipse() (normalizedellipse static method)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse.get_from_opencv_ellipse"]], "get_points_of_ellipses() (in module rave.eye_tracker.ellipse_util)": [[2, "RAVE.eye_tracker.ellipse_util.get_points_of_ellipses"]], "get_test_sub_dataset() (eyetrackerdataset static method)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.get_test_sub_dataset"]], "get_training_sub_dataset() (eyetrackerdataset static method)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.get_training_sub_dataset"]], "get_validation_sub_dataset() (eyetrackerdataset static method)": [[2, "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset.get_validation_sub_dataset"]], "parse_current_annotation() (videosunpacker method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker.parse_current_annotation"]], "process_frame() (eyetrackerdatasetbuilderofflinedataaugmentation method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilderOfflineDataAugmentation.process_frame"]], "process_image_label_pair() (videosunpacker method)": [[2, "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker.process_image_label_pair"]], "rotate_around_image_center() (normalizedellipse method)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse.rotate_around_image_center"]], "to_list() (normalizedellipse method)": [[2, "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse.to_list"]], "training (eyetrackermodel attribute)": [[2, "RAVE.eye_tracker.EyeTrackerModel.EyeTrackerModel.training"]], "face_detection_dir_path (facedetectiondataset attribute)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.FACE_DETECTION_DIR_PATH"]], "fps (class in rave.face_detection.fpshelper)": [[3, "RAVE.face_detection.fpsHelper.FPS"]], "facedetectiondataset (class in rave.face_detection.facedetectiondataset)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset"]], "image_dimensions (facedetectiondataset attribute)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.IMAGE_DIMENSIONS"]], "rave.face_detection.facedetectiondataset": [[3, "module-RAVE.face_detection.FaceDetectionDataset"]], "rave.face_detection.fpshelper": [[3, "module-RAVE.face_detection.fpsHelper"]], "training_mean (facedetectiondataset attribute)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.TRAINING_MEAN"]], "training_std (facedetectiondataset attribute)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.TRAINING_STD"]], "getfps() (fps method)": [[3, "RAVE.face_detection.fpsHelper.FPS.getFps"]], "get_test_sub_dataset() (facedetectiondataset static method)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.get_test_sub_dataset"]], "get_training_sub_dataset() (facedetectiondataset static method)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.get_training_sub_dataset"]], "get_validation_sub_dataset() (facedetectiondataset static method)": [[3, "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset.get_validation_sub_dataset"]], "setfps() (fps method)": [[3, "RAVE.face_detection.fpsHelper.FPS.setFps"]], "start() (fps method)": [[3, "RAVE.face_detection.fpsHelper.FPS.start"]], "writefpstoframe() (fps method)": [[3, "RAVE.face_detection.fpsHelper.FPS.writeFpsToFrame"]]}})