Search.setIndex({"docnames": ["RAVE", "RAVE.common", "RAVE.eye_tracker", "RAVE.facial_detection", "examples", "index"], "filenames": ["RAVE.rst", "RAVE.common.rst", "RAVE.eye_tracker.rst", "RAVE.facial_detection.rst", "examples.rst", "index.rst"], "titles": ["RAVE", "common", "eye_tracker", "facial_detection", "Examples", "Home"], "terms": {"common": 0, "dataset": [0, 2, 3], "datasetbuild": [0, 2], "trainer": 0, "image_util": 0, "eye_track": 0, "eyetrackerdataset": 0, "eyetrackerdatasetbuild": 0, "eyetrackermodel": 0, "normalizedellips": 0, "ellipse_util": 0, "facial_detect": 0, "facedetectiondataset": 0, "facedetectionmodel": 0, "fpshelper": 0, "class": [1, 2, 3], "training_mean": [1, 2, 3], "training_std": [1, 2, 3], "root_path": 1, "sub_dataset_dir": [1, 2, 3], "image_dimens": [1, 2, 3], "base": [1, 2, 3], "handl": [1, 2, 3], "pair": [1, 2, 3], "imag": [1, 2, 3], "label": [1, 2, 3], "ar": [1, 2, 3], "disk": [1, 2, 3], "paramet": [1, 2, 3], "float": [1, 2], "train": [1, 2, 3], "mean": [1, 2], "pixel": [1, 2], "valu": [1, 2], "std": 1, "rooth_path": 1, "string": [1, 2, 3], "root": 1, "path": [1, 2], "name": [1, 2, 3], "directori": [1, 2, 3], "sub": [1, 2, 3], "tupl": [1, 2], "dimens": 1, "shape": [1, 3], "3": [1, 2, 3], "height": [1, 2, 3], "width": [1, 2, 3], "dataset_dir": 1, "images_dir": 1, "images_file_extens": 1, "png": 1, "labels_dir": 1, "test_dir": 1, "test": [1, 2, 3], "training_dir": 1, "validation_dir": 1, "valid": [1, 2, 3], "__getitem__": 1, "idx": 1, "method": [1, 2], "must": [1, 2], "overwritten": [1, 2], "thi": [1, 2], "us": [1, 2, 3], "get": [1, 2, 3, 4], "an": [1, 2, 3], "int": [1, 2], "index": [1, 2, 5], "return": [1, 2, 3], "type": [1, 2, 3], "__init__": 1, "constructor": 1, "list": [1, 2], "each": [1, 2], "channel": 1, "subdataset": 1, "standard": 1, "deviat": 1, "The": [1, 2, 3, 4], "full": 1, "ey": [1, 2], "tracker": [1, 2], "current": [1, 2], "form": 1, "number": [1, 2], "__len__": 1, "element": 1, "__module__": 1, "rave": [1, 2, 3, 4, 5], "__parameters__": 1, "get_image_and_label_from_image_path": 1, "image_path": 1, "str": 1, "get_image_and_label_on_disk": 1, "static": [1, 2, 3], "get_multiple_workers_safe_list_of_path": 1, "build": [1, 2], "prevent": 1, "memori": 1, "leak": 1, "happen": 1, "multipl": 1, "dataload": 1, "worker": 1, "http": [1, 2], "gist": 1, "github": 1, "com": [1, 2], "mprostock": 1, "2850f3cd465155689052f0fa3a177a50": 1, "which": [1, 2], "its": [1, 2], "file": [1, 2], "abstract": 1, "get_test_sub_dataset": [1, 2, 3], "get_training_sub_dataset": [1, 2, 3], "get_validation_sub_dataset": [1, 2, 3], "video": [1, 2, 5], "output_dir_path": [1, 2], "log_nam": [1, 2], "source_dir": [1, 2], "crop_siz": [1, 2], "none": [1, 2], "abc": 1, "It": [1, 2], "take": [1, 2], "extract": [1, 2], "frame": [1, 2, 3], "save": [1, 2], "them": [1, 2], "correspond": [1, 2], "also": [1, 2], "appli": [1, 2], "data": [1, 2], "augment": [1, 2], "transform": [1, 2], "belong": 1, "contain": 1, "displai": 1, "alongsid": 1, "progress": 1, "bar": 1, "termin": 1, "annotations_dir": 1, "annot": [1, 2], "home": [1, 2], "runner": [1, 2], "work": [1, 2], "doc": [1, 2], "videos_dir": [1, 2], "create_directory_if_does_not_exist": 1, "creat": [1, 2], "doe": [1, 2], "exist": 1, "create_images_dataset_with_one_video": 1, "file_nam": [1, 2], "video_path": 1, "One": 1, "per": 1, "repres": [1, 2], "i": [1, 2, 3, 5], "present": 1, "create_images_of_one_video_group": 1, "info": 1, "one": [1, 2], "get_build": [1, 2], "object": [1, 2, 3], "parse_current_annot": [1, 2], "input_image_width": [1, 2], "input_image_height": [1, 2], "pars": [1, 2], "ellips": [1, 2], "defin": [1, 2], "opencv": [1, 2, 3], "all": [1, 2], "true": [1, 2], "wa": [1, 2], "success": [1, 2], "fals": [1, 2], "wasn": [1, 2], "t": [1, 2], "bool": [1, 2, 3], "process_fram": [1, 2], "need": [1, 2], "befor": 1, "numpi": [1, 2], "arrai": [1, 2], "process": [1, 2, 5], "pytorch": [1, 2, 3], "tensor": [1, 2, 3], "process_image_label_pair": [1, 2], "from": [1, 2], "specif": 1, "param": 1, "": [1, 2], "save_image_label_pair": 1, "output_image_tensor": [1, 2], "training_load": 1, "validation_load": 1, "loss_funct": 1, "devic": [1, 2, 3], "model": [1, 2, 3], "optim": 1, "schedul": 1, "root_dir_path": 1, "continue_train": 1, "neural": [1, 2, 3], "network": [1, 2, 3], "functor": 1, "loss": [1, 2], "function": [1, 2], "comput": [1, 2, 3], "perform": [1, 2], "modul": [1, 2, 3], "updat": 1, "weight": 1, "dure": 1, "_lrschedul": 1, "learn": 1, "rate": 1, "whether": 1, "continu": 1, "checkpoint": 1, "model_info_file_nam": 1, "saved_model": 1, "pth": 1, "training_sessions_dir": 1, "training_sess": 1, "compute_training_loss": 1, "epoch": 1, "compute_validation_loss": 1, "load_best_model": 1, "model_dir_path": 1, "best": 1, "version": 1, "torch": 1, "most": 1, "like": 1, "cpu": 1, "cuda": 1, "load_model_and_training_info": 1, "load": 1, "necessari": 1, "inform": 1, "now": 1, "save_model_and_training_info": 1, "some": [1, 2], "other": 1, "time": [1, 2, 3], "terminate_training_thread": 1, "thread": 1, "check": [1, 2], "user": 1, "want": [1, 3], "stop": 1, "have": 1, "been": [1, 2], "execut": [1, 2], "train_with_valid": 1, "nb_epoch": 1, "main": [1, 2], "update_plot": 1, "plot": 1, "end": [1, 2], "show": 1, "so": [1, 2], "far": 1, "apply_image_rot": 1, "image_tensor": 1, "rotation_angle_extremum": 1, "0": [1, 2, 3], "1": [1, 2, 3], "A": [1, 2], "oper": [1, 2], "rotat": [1, 2], "randomli": [1, 2], "select": 1, "angl": [1, 2], "rang": 1, "should": [1, 2], "instead": 1, "you": [1, 4], "wish": 1, "know": 1, "amplitud": 1, "option": [1, 2], "min": 1, "max": [1, 2], "default": [1, 2], "apply_image_transl": 1, "x_extremum": 1, "2": [1, 2], "y_extremum": 1, "translat": [1, 2], "x": [1, 2, 3], "y": [1, 2], "respect": 1, "offset": 1, "apply_image_translation_and_rot": 1, "therot": 1, "box_iou": 1, "box1": 1, "box2": 1, "intersect": 1, "over": 1, "union": 1, "jaccard": 1, "box": 1, "both": 1, "set": 1, "expect": 1, "x1": 1, "y1": 1, "x2": 1, "y2": 1, "format": [1, 2], "n": 1, "4": 1, "m": 1, "nxm": 1, "matrix": 1, "pairwis": 1, "iou": 1, "everi": 1, "boxes1": 1, "boxes2": 1, "check_frontal_fac": 1, "facial_landmark": 1, "thresh_dist_low": 1, "7": 1, "thresh_dist_high": 1, "thresh_high_std": 1, "5": [1, 2, 3], "taken": 1, "tan": 1, "tran": 1, "nguyen": 1, "h": [1, 2], "soan": 1, "duong": 1, "hui": 1, "d": 1, "ta": 1, "chanh": 1, "tr": 1, "trung": 1, "bui": 1, "steven": 1, "q": 1, "truong": 1, "resort": 1, "id": 1, "recoveri": 1, "multi": 1, "face": [1, 3], "track": 1, "surveil": 1, "camera": 1, "ieee": 1, "2021": 1, "ratio": 1, "threshold": 1, "lower": 1, "bound": 1, "higher": 1, "diagon": 1, "distanc": [1, 2], "If": 1, "frontal": 1, "clip_coord": 1, "img_shap": 1, "clip": 1, "xyxi": 1, "do_affine_grid_oper": 1, "phi": [1, 2], "affin": 1, "magnitud": 1, "bbox1": 1, "bbox2": 1, "scale": 1, "smallest": 1, "area": 1, "np": 1, "ndarrai": [1, 3], "xywh": 1, "coord": 1, "inverse_norm": 1, "undo": 1, "normal": [1, 2], "when": 1, "pass": [1, 2, 3], "unorm": 1, "opencv_image_to_tensor": 1, "bgr": 1, "rgb": 1, "scale_coord": 1, "img1_shap": 1, "img0_shap": 1, "ratio_pad": 1, "rescal": 1, "scale_coords_landmark": 1, "tensor_to_opencv_imag": 1, "convert": 1, "xywh2xyxi": 1, "nx4": 1, "w": 1, "where": [1, 2], "xy1": 1, "top": [1, 2], "left": [1, 2], "xy2": 1, "bottom": 1, "right": [1, 3], "xyxy2xywh": 1, "50": 2, "390": 2, "520": 2, "eye_tracker_dir_path": 2, "240": 2, "320": 2, "485": 2, "456": 2, "406": 2, "229": 2, "224": 2, "225": 2, "eyetrackerdatasetonlinedataaugment": 2, "inherit": 2, "overwrit": 2, "certain": 2, "order": 2, "do": 2, "onlin": 2, "eyetrackerfilm": 2, "opencv_devic": 2, "manag": 2, "live": 2, "acquisition_height": 2, "480": 2, "acquisition_width": 2, "640": 2, "call": 2, "program": 2, "free": [2, 5], "eyetrackerinferencedataset": 2, "real": 2, "feed": 2, "infer": 2, "create_dataset": 2, "is_secondary_dataset": 2, "alreadi": 2, "built": 2, "otherwis": 2, "generate_dataset": 2, "gener": 2, "eyetrackerdatasetbuilderofflinedataaugment": 2, "offlin": 2, "apply_translation_and_rot": 2, "reflect": 2, "chang": 2, "parent": 2, "videosunpack": 2, "unpack": 2, "constitut": 2, "dump": 2, "temporari": 2, "can": [2, 3], "tmp_path": 2, "tmp": 2, "builder": 2, "tool": 2, "processed_fram": 2, "original_height": 2, "original_width": 2, "To": [2, 3], "target": 2, "detect": [2, 3], "pupil": 2, "forward": [2, 3], "specifi": 2, "how": 2, "sigmoid": 2, "limit": 2, "ouput": 2, "domain": 2, "converg": 2, "more": 2, "easili": 2, "between": 2, "axi": 2, "pi": 2, "radian": 2, "theta": 2, "For": 2, "exampl": 2, "input": [2, 3], "predict": [2, 3], "k": 2, "b": 2, "five": 2, "center": 2, "posit": 2, "horizont": 2, "vertic": 2, "length": 2, "rel": 2, "longer": 2, "rather": 2, "new": 2, "crop": 2, "crop_bbox": 2, "crope": 2, "e": 2, "associ": 2, "ha": 2, "origin": 2, "pre": 2, "get_from_list": 2, "get_from_opencv_ellips": 2, "center_x": 2, "ellipse_width": 2, "center_i": 2, "ellipse_height": 2, "coordin": 2, "rotate_around_image_cent": 2, "around": 2, "point": 2, "rad": 2, "to_list": 2, "serial": 2, "draw_ellipse_on_imag": 2, "color": 2, "255": 2, "thick": 2, "draw": 2, "drawn": 2, "ellipse_loss_funct": 2, "custom": 2, "develop": 2, "becaus": 2, "mseloss": 2, "directli": 2, "give": 2, "good": 2, "result": 2, "session": 2, "lie": 2, "euclidean": 2, "metric": 2, "get_points_of_ellips": 2, "number_of_point": 2, "polar": 2, "math": 2, "stackexchang": 2, "question": 2, "2645689": 2, "what": 2, "parametr": 2, "equat": 2, "given": 2, "rotatio": 2, "face_detection_dir_path": 3, "face_detect": 3, "800": 3, "0648": 3, "095": 3, "0119": 3, "0695": 3, "0609": 3, "0581": 3, "facial": 3, "confidence_threshold": 3, "intersection_over_union_threshold": 3, "fp": 3, "getfp": 3, "accessor": 3, "setfp": 3, "start": [3, 4], "reset": 3, "part": 3, "we": 3, "after": 3, "init": 3, "writefpstofram": 3, "write": 3, "follow": 4, "help": 4, "come": 4, "soon": 4, "proof": 5, "concept": 5, "aim": 5, "demonstr": 5, "possibl": 5, "combin": 5, "audio": 5, "hear": 5, "aid": 5, "open": 5, "sourc": 5}, "objects": {"RAVE.common": [[1, 0, 0, "-", "Dataset"], [1, 0, 0, "-", "DatasetBuilder"], [1, 0, 0, "-", "Trainer"], [1, 0, 0, "-", "image_utils"]], "RAVE.common.Dataset": [[1, 1, 1, "", "Dataset"]], "RAVE.common.Dataset.Dataset": [[1, 2, 1, "", "DATASET_DIR"], [1, 2, 1, "", "IMAGES_DIR"], [1, 2, 1, "", "IMAGES_FILE_EXTENSION"], [1, 2, 1, "", "LABELS_DIR"], [1, 2, 1, "", "TEST_DIR"], [1, 2, 1, "", "TRAINING_DIR"], [1, 2, 1, "", "VALIDATION_DIR"], [1, 3, 1, "", "__getitem__"], [1, 3, 1, "", "__init__"], [1, 3, 1, "", "__len__"], [1, 2, 1, "", "__module__"], [1, 2, 1, "", "__parameters__"], [1, 3, 1, "", "get_image_and_label_from_image_path"], [1, 3, 1, "", "get_image_and_label_on_disk"], [1, 3, 1, "", "get_multiple_workers_safe_list_of_paths"], [1, 3, 1, "", "get_test_sub_dataset"], [1, 3, 1, "", "get_training_sub_dataset"], [1, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.common.DatasetBuilder": [[1, 1, 1, "", "DatasetBuilder"]], "RAVE.common.DatasetBuilder.DatasetBuilder": [[1, 2, 1, "", "ANNOTATIONS_DIR"], [1, 2, 1, "", "ROOT_PATH"], [1, 2, 1, "", "VIDEOS_DIR"], [1, 3, 1, "", "create_directory_if_does_not_exist"], [1, 3, 1, "", "create_images_dataset_with_one_video"], [1, 3, 1, "", "create_images_of_one_video_group"], [1, 3, 1, "", "get_builders"], [1, 3, 1, "", "parse_current_annotation"], [1, 3, 1, "", "process_frame"], [1, 3, 1, "", "process_image_label_pair"], [1, 3, 1, "", "save_image_label_pair"]], "RAVE.common.Trainer": [[1, 1, 1, "", "Trainer"]], "RAVE.common.Trainer.Trainer": [[1, 2, 1, "", "MODEL_INFO_FILE_NAME"], [1, 2, 1, "", "TRAINING_SESSIONS_DIR"], [1, 3, 1, "", "compute_training_loss"], [1, 3, 1, "", "compute_validation_loss"], [1, 3, 1, "", "load_best_model"], [1, 3, 1, "", "load_model_and_training_info"], [1, 3, 1, "", "save_model_and_training_info"], [1, 3, 1, "", "terminate_training_thread"], [1, 3, 1, "", "train_with_validation"], [1, 3, 1, "", "update_plot"]], "RAVE.common.image_utils": [[1, 4, 1, "", "apply_image_rotation"], [1, 4, 1, "", "apply_image_translation"], [1, 4, 1, "", "apply_image_translation_and_rotation"], [1, 4, 1, "", "box_iou"], [1, 4, 1, "", "check_frontal_face"], [1, 4, 1, "", "clip_coords"], [1, 4, 1, "", "do_affine_grid_operation"], [1, 4, 1, "", "intersection"], [1, 4, 1, "", "inverse_normalize"], [1, 4, 1, "", "opencv_image_to_tensor"], [1, 4, 1, "", "scale_coords"], [1, 4, 1, "", "scale_coords_landmarks"], [1, 4, 1, "", "tensor_to_opencv_image"], [1, 4, 1, "", "xywh2xyxy"], [1, 4, 1, "", "xyxy2xywh"]], "RAVE.eye_tracker": [[2, 0, 0, "-", "EyeTrackerDataset"], [2, 0, 0, "-", "EyeTrackerDatasetBuilder"], [2, 0, 0, "-", "EyeTrackerModel"], [2, 0, 0, "-", "NormalizedEllipse"], [2, 0, 0, "-", "ellipse_util"]], "RAVE.eye_tracker.EyeTrackerDataset": [[2, 1, 1, "", "EyeTrackerDataset"], [2, 1, 1, "", "EyeTrackerDatasetOnlineDataAugmentation"], [2, 1, 1, "", "EyeTrackerFilm"], [2, 1, 1, "", "EyeTrackerInferenceDataset"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerDataset": [[2, 2, 1, "", "CROP_SIZE"], [2, 2, 1, "", "EYE_TRACKER_DIR_PATH"], [2, 2, 1, "", "IMAGE_DIMENSIONS"], [2, 2, 1, "", "TRAINING_MEAN"], [2, 2, 1, "", "TRAINING_STD"], [2, 3, 1, "", "get_test_sub_dataset"], [2, 3, 1, "", "get_training_sub_dataset"], [2, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerFilm": [[2, 2, 1, "", "ACQUISITION_HEIGHT"], [2, 2, 1, "", "ACQUISITION_WIDTH"], [2, 3, 1, "", "end"]], "RAVE.eye_tracker.EyeTrackerDataset.EyeTrackerInferenceDataset": [[2, 2, 1, "", "ACQUISITION_HEIGHT"], [2, 2, 1, "", "ACQUISITION_WIDTH"], [2, 3, 1, "", "end"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder": [[2, 1, 1, "", "EyeTrackerDatasetBuilder"], [2, 1, 1, "", "EyeTrackerDatasetBuilderOfflineDataAugmentation"], [2, 1, 1, "", "VideosUnpacker"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilder": [[2, 3, 1, "", "create_datasets"], [2, 3, 1, "", "generate_dataset"], [2, 3, 1, "", "get_builders"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.EyeTrackerDatasetBuilderOfflineDataAugmentation": [[2, 3, 1, "", "apply_translation_and_rotation"], [2, 3, 1, "", "process_frame"]], "RAVE.eye_tracker.EyeTrackerDatasetBuilder.VideosUnpacker": [[2, 2, 1, "", "TMP_PATH"], [2, 3, 1, "", "get_builders"], [2, 3, 1, "", "parse_current_annotation"], [2, 3, 1, "", "process_image_label_pair"]], "RAVE.eye_tracker.EyeTrackerModel": [[2, 1, 1, "", "EyeTrackerModel"]], "RAVE.eye_tracker.EyeTrackerModel.EyeTrackerModel": [[2, 3, 1, "", "forward"], [2, 2, 1, "", "training"]], "RAVE.eye_tracker.NormalizedEllipse": [[2, 1, 1, "", "NormalizedEllipse"]], "RAVE.eye_tracker.NormalizedEllipse.NormalizedEllipse": [[2, 3, 1, "", "crop"], [2, 3, 1, "", "get_from_list"], [2, 3, 1, "", "get_from_opencv_ellipse"], [2, 3, 1, "", "rotate_around_image_center"], [2, 3, 1, "", "to_list"]], "RAVE.eye_tracker.ellipse_util": [[2, 4, 1, "", "draw_ellipse_on_image"], [2, 4, 1, "", "ellipse_loss_function"], [2, 4, 1, "", "get_points_of_ellipses"]], "RAVE.face_detection": [[3, 0, 0, "-", "FaceDetectionDataset"], [3, 0, 0, "-", "FaceDetectionModel"], [3, 0, 0, "-", "fpsHelper"]], "RAVE.face_detection.FaceDetectionDataset": [[3, 1, 1, "", "FaceDetectionDataset"]], "RAVE.face_detection.FaceDetectionDataset.FaceDetectionDataset": [[3, 2, 1, "", "FACE_DETECTION_DIR_PATH"], [3, 2, 1, "", "IMAGE_DIMENSIONS"], [3, 2, 1, "", "TRAINING_MEAN"], [3, 2, 1, "", "TRAINING_STD"], [3, 3, 1, "", "get_test_sub_dataset"], [3, 3, 1, "", "get_training_sub_dataset"], [3, 3, 1, "", "get_validation_sub_dataset"]], "RAVE.face_detection.FaceDetectionModel": [[3, 1, 1, "", "FaceDetectionModel"]], "RAVE.face_detection.FaceDetectionModel.FaceDetectionModel": [[3, 2, 1, "", "CONFIDENCE_THRESHOLD"], [3, 2, 1, "", "INTERSECTION_OVER_UNION_THRESHOLD"], [3, 3, 1, "", "forward"], [3, 2, 1, "", "training"]], "RAVE.face_detection.fpsHelper": [[3, 1, 1, "", "FPS"]], "RAVE.face_detection.fpsHelper.FPS": [[3, 3, 1, "", "getFps"], [3, 3, 1, "", "setFps"], [3, 3, 1, "", "start"], [3, 3, 1, "", "writeFpsToFrame"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"rave": 0, "common": 1, "dataset": 1, "datasetbuild": 1, "trainer": 1, "image_util": 1, "eye_track": 2, "eyetrackerdataset": 2, "eyetrackerdatasetbuild": 2, "eyetrackermodel": 2, "normalizedellips": 2, "ellipse_util": 2, "facial_detect": 3, "facedetectiondataset": 3, "facedetectionmodel": 3, "fpshelper": 3, "exampl": 4, "home": 5}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 56}})